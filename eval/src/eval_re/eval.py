import sys
import os
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading



# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..'))
sys.path.insert(0, project_root)

from backend.api.common.database import get_db_connection
from backend.api.student.recommendations.new_knowledge import get_current_module, get_next_learnable_node_in_module
import requests
import json
import time
from collections import defaultdict
from fastapi import HTTPException
from datetime import datetime

# --- æ ¸å¿ƒæ•°æ®å¤„ç†å‡½æ•° ---
def get_user_profile_data(user_id: int, last_n: int = 30):
    """
    ä¸ºæŒ‡å®šç”¨æˆ·æå–å¹¶å¤„ç†è¿‘æœŸå­¦ä¹ æ•°æ®ï¼Œç”Ÿæˆåˆ†ææ‘˜è¦ã€‚
    """
    conn = get_db_connection()
    
    try:
        # 1. æŸ¥è¯¢è¿‘æœŸç­”é¢˜è®°å½•ï¼Œå¹¶JOINä¸Šé¢˜ç›®å’ŒçŸ¥è¯†ç‚¹ä¿¡æ¯ï¼Œæœ€é‡è¦çš„æ˜¯è·å–å…¶é«˜é˜¶"é¢†åŸŸ"
        # è¿™ä¸ªæŸ¥è¯¢éå¸¸å…³é”®ï¼Œå®ƒä¸€æ¬¡æ€§è·å–äº†æˆ‘ä»¬éœ€è¦çš„æ‰€æœ‰åŸå§‹ä¿¡æ¯
        sql = """
            -- è¿™æ˜¯æœ€ç»ˆç‰ˆçš„ã€èƒ½ç²¾ç¡®æŸ¥æ‰¾"ç« èŠ‚"çš„æŸ¥è¯¢
            -- è¿™ä¸ªæŸ¥è¯¢çš„ç›®çš„æ˜¯ä¸ºäº†æŒ‰"å…·ä½“çŸ¥è¯†ç‚¹"è¿›è¡Œåˆ†ç»„ç»Ÿè®¡
            SELECT
                ua.is_correct,
                ua.diagnosis_json,
                kn.node_id,
                kn.node_name
            FROM
                user_answers AS ua
            JOIN
                question_to_node_mapping AS qnm ON ua.question_id = qnm.question_id
            JOIN
                knowledge_nodes AS kn ON qnm.node_id = kn.node_id
            WHERE
                ua.user_id = ? -- ç­›é€‰æŒ‡å®šç”¨æˆ·
            ORDER BY
                ua.timestamp DESC
            LIMIT ?; -- é™åˆ¶åˆ†ææœ€è¿‘çš„Næ¡è®°å½•
        """
        recent_answers = conn.execute(sql, (user_id, last_n)).fetchall()
        # print(recent_answers)

        if not recent_answers:
            return {"message": "è¯¥ç”¨æˆ·å°šæ— è¶³å¤Ÿçš„å­¦ä¹ è®°å½•è¿›è¡Œåˆ†æã€‚"}

        # 2. åœ¨Pythonä¸­è¿›è¡Œåˆ†ç»„å’Œç»Ÿè®¡
        # defaultdictå¯ä»¥è®©æˆ‘ä»¬æ–¹ä¾¿åœ°å¤„ç†åˆ†ç»„
        domain_stats = defaultdict(lambda: {
            "interaction_count": 0, 
            "correct_count": 0, 
            "scores": defaultdict(list)
        })

        for answer in recent_answers:
            node_id = answer['node_id']
            node_name = answer['node_name']
            # ä½¿ç”¨çŸ¥è¯†ç‚¹åç§°ä½œä¸ºåˆ†ç»„é”®
            if node_name not in domain_stats:
                domain_stats[node_name]["node_id"] = node_id
            domain_stats[node_name]["interaction_count"] += 1
            if answer['is_correct']:
                domain_stats[node_name]["correct_count"] += 1
            
            # è§£ædiagnosis_jsonæ¥ç´¯åŠ å››ä¸ªç»´åº¦çš„åˆ†æ•°
            if answer['diagnosis_json']:
                try:
                    diagnosis = json.loads(answer['diagnosis_json'])
                    # print(f"è¯Šæ–­æ•°æ®: {diagnosis}")  # æ‰“å°è¯Šæ–­æ•°æ®
                    for dim in diagnosis.get('assessment_dimensions', []):
                        dimension_name = dim['dimension'].split(' ')[0] # 'çŸ¥è¯†æŒæ¡' -> 'çŸ¥è¯†æŒæ¡'
                        domain_stats[node_name]["scores"][dimension_name].append(dim['score'])
                        # print(f"ç»´åº¦: {dimension_name}, åˆ†æ•°: {dim['score']}")  # æ‰“å°ç»´åº¦å’Œåˆ†æ•°
                except (json.JSONDecodeError, KeyError):
                    # print(f"JSONè§£æé”™è¯¯æˆ–ç¼ºå°‘é”®: {answer['diagnosis_json']}")  # æ‰“å°é”™è¯¯ä¿¡æ¯
                    continue

        # 3. æ ¼å¼åŒ–è¾“å‡ºï¼Œè®¡ç®—å¹³å‡åˆ†
        analysis_by_domain = []
        total_interactions = len(recent_answers)
        total_correct = sum(1 for ans in recent_answers if ans['is_correct'])

        for domain, stats in domain_stats.items():
            avg_scores = {}
            for dim_name, score_list in stats["scores"].items():
                # print(f"ç»´åº¦: {dim_name}, æ‰€æœ‰åˆ†æ•°: {score_list}")
                avg_scores[dim_name] = round(sum(score_list) / len(score_list), 2) if score_list else 0.0

            analysis_by_domain.append({
                "node_id": stats["node_id"],  # æ·»åŠ node_id
                "node_name": domain,  # æ›´æ”¹å­—æ®µåä»¥åæ˜ è¿™æ˜¯çŸ¥è¯†ç‚¹åç§°è€Œéé¢†åŸŸåç§°
                "interaction_count": stats["interaction_count"],
                "accuracy": round(stats["correct_count"] / stats["interaction_count"], 2),
                "average_scores": avg_scores
            })

        # 4. ç»„è£…æˆæœ€ç»ˆçš„ã€å°†è¦å‘é€ç»™ç”»åƒåˆ†æå¸ˆAgentçš„JSON
        # print(final_payload)
        final_payload = {
            "user_id": user_id,
            "analysis_window": total_interactions,
            "overall_recent_accuracy": round(total_correct / total_interactions, 2),
            "analysis_by_node": analysis_by_domain  # æ›´æ–°å­—æ®µåä»¥åæ˜ è¿™æ˜¯æŒ‰çŸ¥è¯†ç‚¹åˆ†æè€Œéé¢†åŸŸ
        }
        # print(final_payload)
        
        return final_payload

    except Exception as e:
        print(f"å¤„ç†ç”¨æˆ·{user_id}çš„æ•°æ®æ—¶å‡ºé”™: {e}")
        raise
    finally:
        conn.close()


def get_knowledge_nodes():
    """è·å–æ‰€æœ‰çŸ¥è¯†èŠ‚ç‚¹"""
    try:
        conn = get_db_connection()
        cursor = conn.execute("SELECT node_id, node_name, node_difficulty, node_type FROM knowledge_nodes")
        
        nodes = {}
        for row in cursor.fetchall():
            if row['node_type'] != 'æ¨¡å—':
                nodes[row["node_id"]] = row["node_name"]
        # print(nodes.values())
        conn.close()
        return nodes.values()
    except Exception as e:
        print(e)


def get_knowledge_map(user_id: str):
    """è·å–ç”¨æˆ·çŸ¥è¯†å›¾è°±å’Œæ¨¡å—å­¦ä¹ è¿›åº¦"""
    try:
        # æ¨¡å—é¡ºåºå®šä¹‰
        MODULE_ORDER = [
            "æ¦‚ç‡è®ºçš„åŸºæœ¬æ¦‚å¿µ",
            "æ¦‚ç‡è¿ç®—è¿›é˜¶", 
            "éšæœºå˜é‡åŠå…¶åˆ†å¸ƒ",
            "æ•°å­—ç‰¹å¾ä¸å…³ç³»",
            "æé™å®šç†",
            "æ•°ç†ç»Ÿè®¡"
        ]
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # è·å–ç”¨æˆ·æŒæ¡åº¦æ•°æ®
        cursor.execute("""
            SELECT 
                kn.node_id,
                kn.node_name,
                kn.node_difficulty,
                kn.level,
                COALESCE(unm.mastery_score, 0.0) as mastery_score
            FROM knowledge_nodes kn
            LEFT JOIN user_node_mastery unm ON kn.node_id = unm.node_id AND unm.user_id = ?
            WHERE kn.node_type != 'æ¨¡å—'
            ORDER BY kn.node_id
        """, (user_id,))
        
        all_nodes = cursor.fetchall()
        user_mastery = {str(row['node_id']): row['mastery_score'] for row in all_nodes}
        
        # æ„å»ºæ¨¡å—ä¿¡æ¯å­—å…¸
        modules_info = {}
        completed_modules = []
        current_module = None
        current_module_info = None
        
        for module_name in MODULE_ORDER:
            # è·å–æ¨¡å—åŒ…å«çš„æ‰€æœ‰èŠ‚ç‚¹
            cursor.execute("""
                SELECT target_node_id as node_id, target_kn.node_name
                FROM knowledge_edges ke
                JOIN knowledge_nodes kn ON ke.source_node_id = kn.node_id
                JOIN knowledge_nodes target_kn ON ke.target_node_id = target_kn.node_id
                WHERE kn.node_name = ? AND ke.relation_type = 'åŒ…å«'
            """, (module_name,))
            
            module_nodes = cursor.fetchall()
            if not module_nodes:
                continue
                
            # ç»Ÿè®¡æ¨¡å—å†…èŠ‚ç‚¹çš„æŒæ¡æƒ…å†µ
            mastered_nodes = []
            unmastered_nodes = []
            
            for node in module_nodes:
                node_id_str = str(node['node_id'])
                mastery_score = user_mastery.get(node_id_str, 0.0)
                
                if mastery_score >= 0.8:
                    mastered_nodes.append(node['node_name'])
                else:
                    unmastered_nodes.append(node['node_name'])
            
            # åˆ¤æ–­æ¨¡å—æ˜¯å¦å®Œæˆ
            is_completed = len(unmastered_nodes) == 0
            
            modules_info[module_name] = {
                'mastered_nodes': mastered_nodes,
                'unmastered_nodes': unmastered_nodes,
                'is_completed': is_completed,
                'total_nodes': len(module_nodes),
                'mastered_count': len(mastered_nodes)
            }
            
            if is_completed:
                completed_modules.append(module_name)
            elif current_module is None:  # ç¬¬ä¸€ä¸ªæœªå®Œæˆçš„æ¨¡å—å°±æ˜¯å½“å‰å­¦ä¹ æ¨¡å—
                current_module = module_name
                current_module_info = modules_info[module_name]
        
        # æ„å»ºè‡ªç„¶è¯­è¨€æè¿°
        description_parts = []
        
        # å·²å®Œæˆçš„æ¨¡å—
        if completed_modules:
            description_parts.append(f"ç”¨æˆ·å·²ç»å®Œæˆäº†{len(completed_modules)}ä¸ªæ¨¡å—çš„å­¦ä¹ ï¼š{', '.join(completed_modules)}")
        else:
            description_parts.append("ç”¨æˆ·å°šæœªå®Œæˆä»»ä½•æ¨¡å—çš„å­¦ä¹ ")
        
        # å½“å‰å­¦ä¹ æ¨¡å—
        if current_module and current_module_info:
            mastered_str = f"å·²æŒæ¡{len(current_module_info['mastered_nodes'])}ä¸ªçŸ¥è¯†ç‚¹" if current_module_info['mastered_nodes'] else "å°šæœªæŒæ¡ä»»ä½•çŸ¥è¯†ç‚¹"
            unmastered_str = f"è¿˜éœ€å­¦ä¹ {len(current_module_info['unmastered_nodes'])}ä¸ªçŸ¥è¯†ç‚¹" if current_module_info['unmastered_nodes'] else "å·²å®Œæˆæ‰€æœ‰çŸ¥è¯†ç‚¹"
            
            description_parts.append(f"ç›®å‰æ­£åœ¨å­¦ä¹ '{current_module}'æ¨¡å—ï¼Œ{mastered_str}ï¼Œ{unmastered_str}")
            
            if current_module_info['mastered_nodes']:
                description_parts.append(f"å·²æŒæ¡çš„çŸ¥è¯†ç‚¹åŒ…æ‹¬ï¼š{', '.join(current_module_info['mastered_nodes'])}")
            
            if current_module_info['unmastered_nodes']:
                description_parts.append(f"å¾…å­¦ä¹ çš„çŸ¥è¯†ç‚¹åŒ…æ‹¬ï¼š{', '.join(current_module_info['unmastered_nodes'])}")
        else:
            description_parts.append("æ­å–œï¼ç”¨æˆ·å·²å®Œæˆæ‰€æœ‰æ¨¡å—çš„å­¦ä¹ ")
        
        natural_language_description = "ã€‚".join(description_parts) + "ã€‚"
        # print(natural_language_description)
        
        # è¿”å›åŸæœ‰çš„å·²æŒæ¡çŸ¥è¯†ç‚¹åˆ—è¡¨ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰å’Œæ–°å¢çš„æ¨¡å—ä¿¡æ¯
        mastered_knowledge_list = [row['node_name'] for row in all_nodes if row['mastery_score'] > 0.8]
        
        conn.close()
        
        # è¿”å›åŒ…å«æ¨¡å—ä¿¡æ¯çš„å­—å…¸
        return {
            'mastered_knowledge_list': mastered_knowledge_list,  # åŸæœ‰æ ¼å¼ï¼Œä¿æŒå…¼å®¹æ€§
            'modules_info': modules_info,
            'natural_language_description': natural_language_description,
            'completed_modules': completed_modules,
            'current_module': current_module
        }
        
    except Exception as e:
        print(f"è·å–çŸ¥è¯†å›¾è°±æ—¶å‡ºé”™: {e}")
        return []

def get_users():
    """è·å–ç”¨æˆ·åˆ—è¡¨"""
    try:
        conn = get_db_connection()
        cursor = conn.execute("SELECT user_id, username, role FROM users")
        # åªè¿”å›è§’è‰²ä¸ºå­¦ç”Ÿçš„ç”¨æˆ·
        users = [{"user_id": row["user_id"], "username": row["username"], "role": row["role"]} 
                for row in cursor.fetchall() 
                if row["role"] == "student"]
        conn.close()
        return users
    except Exception as e:
        print(e)


# --- AI APIè°ƒç”¨å‡½æ•° ---
def call_ai_re_api(profile_data):
    """
    è¿™æ˜¯æˆ‘ä»¬ç³»ç»Ÿçš„æ¨èç®—æ³•
    
    Args:
        profile_data (dict): ç”¨æˆ·å­¦ä¹ æ•°æ®åˆ†æç»“æœ
        
    Returns:
        tuple: (decision_reasoning, strategic_decision) è¯Šæ–­ç†ç”±å’Œç­–ç•¥å†³ç­–
        
    Raises:
        HTTPException: å½“APIè°ƒç”¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    # print(f"ğŸ¤– å¼€å§‹è°ƒç”¨AIæ¨èAPI")      
    
    url = "https://xingchen-api.xf-yun.com/workflow/v1/chat/completions"
    
    payload = json.dumps({
    "flow_id": "7352207588747141122",
    "parameters": {
        "AGENT_USER_INPUT": json.dumps(profile_data),
    },
    "ext": {
        "bot_id": "workflow",
        "caller": "workflow"
    },
    "stream": False,
    })
    headers = {
    'Authorization': 'Bearer 4cec7267c3353726a2f1656cb7c0ec37:NDk0MDk0N2JiYzg0ZTgxMzVlNmRkM2Fh',
    'Content-Type': 'application/json',
    'Accept': '*/*',
    'Host': 'xingchen-api.xf-yun.com',
    'Connection': 'keep-alive'
    }
    
    # print(f"ğŸŒ å‘é€APIè¯·æ±‚åˆ°: {url}")
    response = requests.request("POST", url, headers=headers, data=payload).json()
    # print("ğŸ“¨ AI APIå“åº”æˆåŠŸ")
    
    # æ£€æŸ¥å“åº”æ˜¯å¦æˆåŠŸ
    if 'choices' not in response or not response['choices'] or 'delta' not in response['choices'][0]:
        print("âŒ AI APIå“åº”æ ¼å¼é”™è¯¯")
        raise HTTPException(status_code=500, detail="AIç”Ÿæˆå­¦ä¹ ç›®æ ‡å¤±è´¥ï¼šå“åº”æ ¼å¼é”™è¯¯")
        
    content = response['choices'][0]['delta'].get('content')
    if not content:
        print("âŒ AI APIè¿”å›å†…å®¹ä¸ºç©º")
        raise HTTPException(status_code=500, detail="AIè¯Šæ–­å¤±è´¥")

    decision_reasoning = content.split('##')[0]
    strategic_decision = json.loads(content.split('##')[1])

    mission_type = strategic_decision.get('mission_type')

    if mission_type == "NEW_KNOWLEDGE":
        conn = get_db_connection()
        cursor = conn.cursor()
        module_name = get_current_module(cursor, profile_data['user_id'])
        strategic_decision['target']['type'] = get_next_learnable_node_in_module(cursor, profile_data['user_id'], module_name)
        conn.close()
    
    # print(f"âœ… AIæ¨èå†…å®¹: {content}")
    
    return {
        "decision_reasoning": decision_reasoning,
        "strategic_decision": strategic_decision
    }


def call_re_api(input_text):
    """
    è°ƒç”¨AIæ¨èAPI
    """
    try:
        url = "https://xingchen-api.xf-yun.com/workflow/v1/chat/completions"
        
        payload = json.dumps({
            "flow_id": "7357270047910617090",
            "parameters": {
                "AGENT_USER_INPUT": input_text,
            },
            "ext": {
                "bot_id": "workflow",
                "caller": "workflow"
            },
            "stream": False,
        })
        headers = {
            'Authorization': 'Bearer 4cec7267c3353726a2f1656cb7c0ec37:NDk0MDk0N2JiYzg0ZTgxMzVlNmRkM2Fh',
            'Content-Type': 'application/json',
            'Accept': '*/*',
            'Host': 'xingchen-api.xf-yun.com',
            'Connection': 'keep-alive'
        }
        
        response = requests.request("POST", url, headers=headers, data=payload).json()
        
        # æ£€æŸ¥å“åº”æ˜¯å¦æˆåŠŸ
        if 'choices' not in response or not response['choices'] or 'delta' not in response['choices'][0]:
            return {"error": "AI APIå“åº”æ ¼å¼é”™è¯¯"}
            
        content = response['choices'][0]['delta'].get('content')
        # print(content)

        if not content:
            print("âŒ AI APIè¿”å›å†…å®¹ä¸ºç©º")
            raise HTTPException(status_code=500, detail="AIè¯Šæ–­å¤±è´¥")
        decision_reasoning = content.split('##')[0]
        strategic_decision = json.loads(content.split('##')[1])
            
        return {
            "decision_reasoning": decision_reasoning,
            "strategic_decision": strategic_decision
        }
    except Exception as e:
        return {"error": str(e)}


def process_user(user, nodes):
    """å¤„ç†å•ä¸ªç”¨æˆ·çš„è¯„ä¼°ä»»åŠ¡"""
    try:
        user_id = user["user_id"]

        if user_id < 50:
            return None

        knowledge_map_data = get_knowledge_map(user_id)
        
        user_profile = get_user_profile_data(user_id, last_n=20)
        
        # ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°å’Œå·²æŒæ¡çŸ¥è¯†ç‚¹åˆ—è¡¨æ„å»ºè¾“å…¥æ–‡æœ¬
        if isinstance(knowledge_map_data, dict):
            natural_description = knowledge_map_data.get('natural_language_description', '')
            mastered_list = knowledge_map_data.get('mastered_knowledge_list', [])
            
            # æ„å»ºæ›´ä¸°å¯Œçš„è¾“å…¥æ–‡æœ¬
            # knowledge_info = f"å­¦ä¹ è¿›åº¦æè¿°ï¼š{natural_description}\nå·²æŒæ¡çŸ¥è¯†ç‚¹ï¼š{mastered_list}"
            input_text = str(user_profile) + "##" + natural_description
            
            if len(mastered_list) == 0:
                input_text = str(user_profile) + "##" + "ç”¨æˆ·æœªå­¦ä¹ ä»»ä½•çŸ¥è¯†ç‚¹"
        else:
            # å…¼å®¹æ—§æ ¼å¼ï¼ˆå¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼‰
            input_text = str(user_profile) + "##" + natural_description
            if len(knowledge_map_data) == 0:
                input_text = str(user_profile) + "##" + "ç”¨æˆ·æœªå­¦ä¹ ä»»ä½•çŸ¥è¯†ç‚¹" + "##" + str(nodes)

        # è·å–ä¸¤ä¸ªAPIçš„ç»“æœ
        result_re = call_re_api(input_text)
        # result_multi_re = call_multi_re_api(input_text)
        result_ai_re = call_ai_re_api(user_profile)
        
        # è¿”å›ç”¨æˆ·ç»“æœ
        return user_id, {
            'prompt': input_text,
            "rule_based_recommendation": result_re,
            # "multi_expert_recommendation": result_multi_re,
            "ai_recommendation": result_ai_re
        }
    except Exception as e:
        print(f"âŒ å¤„ç†ç”¨æˆ· {user['user_id']} æ—¶å‡ºé”™: {e}")
        return user['user_id'], {"error": str(e)}


def main():
    users = get_users()
    nodes = get_knowledge_nodes()
    
    print(f"ğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç† {len(users)} ä¸ªç”¨æˆ·çš„è¯„ä¼°ä»»åŠ¡...")
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_file = f"/Users/cuiziliang/Projects/unveiling-the-list/eval/eval_data/æ¨è/eval_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    # åˆå§‹åŒ–JSONæ–‡ä»¶
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("{\n")
    
    # åˆ›å»ºæ–‡ä»¶å†™å…¥é”
    file_lock = threading.Lock()
    
    # ç»Ÿè®¡å˜é‡
    success_count = 0
    error_count = 0
    processed_count = 0
    
    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶è¡Œå¤„ç†
    max_workers = min(2, len(users))  # æœ€å¤š2ä¸ªå¹¶å‘çº¿ç¨‹ï¼Œé¿å…è¿‡å¤šè¯·æ±‚
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_user = {executor.submit(process_user, user, nodes): user for user in users}
        
        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
        with tqdm(total=len(users), desc="ğŸ”„ å¤„ç†ç”¨æˆ·è¯„ä¼°") as pbar:
            for future in as_completed(future_to_user):
                user = future_to_user[future]
                result = future.result()
                if result is None:
                    continue
                try:
                    user_id, result = future.result()
                    
                    # ç«‹å³å†™å…¥æ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
                    with file_lock:
                        with open(output_file, "a", encoding="utf-8") as f:
                            # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªç”¨æˆ·ï¼Œæ·»åŠ é€—å·
                            if processed_count > 0:
                                f.write(",\n")
                            # å†™å…¥ç”¨æˆ·ç»“æœ
                            f.write(f'  "{user_id}": {json.dumps(result, ensure_ascii=False, indent=2).replace(chr(10), chr(10) + "  ")}')
                        
                        processed_count += 1
                        if 'error' not in result:
                            success_count += 1
                        else:
                            error_count += 1
                    
                    pbar.set_postfix({"å½“å‰ç”¨æˆ·": user['username'], "å·²å®Œæˆ": processed_count})
                    
                except Exception as e:
                    print(f"âŒ ç”¨æˆ· {user['username']} å¤„ç†å¤±è´¥: {e}")
                    error_result = {"error": str(e)}
                    
                    # ç«‹å³å†™å…¥é”™è¯¯ç»“æœï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
                    with file_lock:
                        with open(output_file, "a", encoding="utf-8") as f:
                            # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªç”¨æˆ·ï¼Œæ·»åŠ é€—å·
                            if processed_count > 0:
                                f.write(",\n")
                            # å†™å…¥é”™è¯¯ç»“æœ
                            f.write(f'  "{user["user_id"]}": {json.dumps(error_result, ensure_ascii=False, indent=2).replace(chr(10), chr(10) + "  ")}')
                        
                        processed_count += 1
                        error_count += 1
                    
                finally:
                    pbar.update(1)
    
    # å®ŒæˆJSONæ–‡ä»¶
    with open(output_file, "a", encoding="utf-8") as f:
        f.write("\n}")
        
    print(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {output_file}")
    print(f"ğŸ“Š æˆåŠŸå¤„ç†: {success_count} ä¸ªç”¨æˆ·")
    print(f"âŒ å¤„ç†å¤±è´¥: {error_count} ä¸ªç”¨æˆ·")
    print(f"ğŸ“ æ€»è®¡å¤„ç†: {processed_count} ä¸ªç”¨æˆ·")


if __name__ == "__main__":
    main()
