#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š ç”¨æˆ·çŸ¥è¯†ç‚¹æŒæ¡åº¦æ•°æ®å¯¼å‡ºå·¥å…·

åŠŸèƒ½:
1. ä»æ•°æ®åº“ä¸­æå–ç”¨æˆ·çŸ¥è¯†ç‚¹æŒæ¡åº¦æ•°æ®
2. å¯¼å‡ºä¸ºCSVæ ¼å¼æ–‡ä»¶
3. æ‰“å°è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

è¾“å‡ºæ ¼å¼:
user_id,node_id,mastery_score,username,node_name,node_difficulty,level
"""

import sqlite3
import csv
import os
from datetime import datetime
import pandas as pd

# é…ç½®
DB_FILE = "../my_database.db"
OUTPUT_CSV = "user_mastery_data.csv"

def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    if not os.path.exists(DB_FILE):
        raise FileNotFoundError(f"âŒ æ•°æ®åº“æ–‡ä»¶ {DB_FILE} ä¸å­˜åœ¨")
    
    conn = sqlite3.connect(DB_FILE)
    conn.row_factory = sqlite3.Row
    return conn

def extract_mastery_data():
    """æå–ç”¨æˆ·çŸ¥è¯†ç‚¹æŒæ¡åº¦æ•°æ® ğŸ“ˆ"""
    print("ğŸš€ å¼€å§‹æå–ç”¨æˆ·çŸ¥è¯†ç‚¹æŒæ¡åº¦æ•°æ®...")
    print("=" * 60)
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # æŸ¥è¯¢æŒæ¡åº¦æ•°æ®ï¼Œå…³è”ç”¨æˆ·å’ŒçŸ¥è¯†ç‚¹ä¿¡æ¯
        query = """
        SELECT
            unm.mastery_id,
            unm.user_id,
            unm.node_id,
            unm.mastery_score,
            u.username,
            kn.node_name,
            kn.node_difficulty,
            kn.level,
            kn.node_type
        FROM user_node_mastery unm
        JOIN users u ON unm.user_id = u.user_id
        JOIN knowledge_nodes kn ON unm.node_id = kn.node_id
        WHERE u.role = 'student'
        ORDER BY unm.user_id, unm.node_id
        """
        
        print("ğŸ“Š æ‰§è¡Œæ•°æ®æŸ¥è¯¢...")
        cursor.execute(query)
        mastery_data = cursor.fetchall()
        
        if not mastery_data:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æŒæ¡åº¦æ•°æ®")
            return []
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data_list = [dict(row) for row in mastery_data]
        
        print(f"âœ… æˆåŠŸæå– {len(data_list)} æ¡æŒæ¡åº¦è®°å½•")
        
        return data_list
        
    except Exception as e:
        print(f"âŒ æ•°æ®æå–å¤±è´¥: {str(e)}")
        raise
    finally:
        conn.close()

def print_statistics(data_list):
    """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ ğŸ“ˆ"""
    if not data_list:
        return
    
    print("\nğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
    print("=" * 60)
    
    # è½¬æ¢ä¸ºDataFrameä¾¿äºåˆ†æ
    df = pd.DataFrame(data_list)
    
    # åŸºæœ¬ç»Ÿè®¡
    total_records = len(df)
    unique_users = df['user_id'].nunique()
    unique_nodes = df['node_id'].nunique()
    
    print(f"ğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
    print(f"   æ€»è®°å½•æ•°: {total_records:,}")
    print(f"   ç”¨æˆ·æ•°é‡: {unique_users}")
    print(f"   çŸ¥è¯†ç‚¹æ•°é‡: {unique_nodes}")
    print(f"   å¹³å‡æ¯ç”¨æˆ·æŒæ¡åº¦è®°å½•: {total_records/unique_users:.1f}")
    
    # æŒæ¡åº¦åˆ†å¸ƒç»Ÿè®¡
    print(f"\nğŸ“ˆ æŒæ¡åº¦åˆ†å¸ƒ:")
    mastery_stats = df['mastery_score'].describe()
    print(f"   æœ€å°å€¼: {mastery_stats['min']:.3f}")
    print(f"   æœ€å¤§å€¼: {mastery_stats['max']:.3f}")
    print(f"   å¹³å‡å€¼: {mastery_stats['mean']:.3f}")
    print(f"   ä¸­ä½æ•°: {mastery_stats['50%']:.3f}")
    print(f"   æ ‡å‡†å·®: {mastery_stats['std']:.3f}")
    
    # æŒæ¡åº¦ç­‰çº§åˆ†å¸ƒ
    print(f"\nğŸ¯ æŒæ¡åº¦ç­‰çº§åˆ†å¸ƒ:")
    excellent = len(df[df['mastery_score'] >= 0.8])
    good = len(df[(df['mastery_score'] >= 0.6) & (df['mastery_score'] < 0.8)])
    fair = len(df[(df['mastery_score'] >= 0.4) & (df['mastery_score'] < 0.6)])
    poor = len(df[df['mastery_score'] < 0.4])
    
    print(f"   ğŸŒŸ ä¼˜ç§€ (â‰¥0.8): {excellent:,} ({excellent/total_records*100:.1f}%)")
    print(f"   ğŸ‘ è‰¯å¥½ (0.6-0.8): {good:,} ({good/total_records*100:.1f}%)")
    print(f"   ğŸ“š ä¸€èˆ¬ (0.4-0.6): {fair:,} ({fair/total_records*100:.1f}%)")
    print(f"   ğŸ“– å¾…æé«˜ (<0.4): {poor:,} ({poor/total_records*100:.1f}%)")
    
    # æŒ‰ç”¨æˆ·ç»Ÿè®¡
    print(f"\nğŸ‘¥ ç”¨æˆ·æŒæ¡åº¦ç»Ÿè®¡:")
    user_stats = df.groupby(['user_id', 'username']).agg({
        'mastery_score': ['count', 'mean', 'std'],
        'node_id': 'count'
    }).round(3)
    
    for (user_id, username), stats in user_stats.iterrows():
        count = int(stats[('mastery_score', 'count')])
        mean_score = stats[('mastery_score', 'mean')]
        std_score = stats[('mastery_score', 'std')]
        
        print(f"   ğŸ‘¤ {username} (ID:{user_id}): {count}ä¸ªçŸ¥è¯†ç‚¹, å¹³å‡æŒæ¡åº¦:{mean_score:.3f}, æ ‡å‡†å·®:{std_score:.3f}")
    
    # æŒ‰çŸ¥è¯†ç‚¹ç±»å‹ç»Ÿè®¡
    if 'node_type' in df.columns:
        print(f"\nğŸ“š çŸ¥è¯†ç‚¹ç±»å‹åˆ†å¸ƒ:")
        type_stats = df.groupby('node_type').agg({
            'mastery_score': ['count', 'mean'],
            'node_id': 'nunique'
        }).round(3)
        
        for node_type, stats in type_stats.iterrows():
            count = int(stats[('mastery_score', 'count')])
            mean_score = stats[('mastery_score', 'mean')]
            unique_nodes = int(stats[('node_id', 'nunique')])
            
            print(f"   ğŸ“– {node_type}: {unique_nodes}ä¸ªçŸ¥è¯†ç‚¹, {count}æ¡è®°å½•, å¹³å‡æŒæ¡åº¦:{mean_score:.3f}")
    
    # æŒ‰éš¾åº¦ç»Ÿè®¡
    print(f"\nâ­ çŸ¥è¯†ç‚¹éš¾åº¦ä¸æŒæ¡åº¦å…³ç³»:")
    # å°†éš¾åº¦åˆ†ç»„
    df['difficulty_group'] = pd.cut(df['node_difficulty'], 
                                   bins=[0, 0.3, 0.6, 1.0], 
                                   labels=['ç®€å•', 'ä¸­ç­‰', 'å›°éš¾'])
    
    difficulty_stats = df.groupby('difficulty_group').agg({
        'mastery_score': ['count', 'mean'],
        'node_id': 'nunique'
    }).round(3)
    
    for difficulty, stats in difficulty_stats.iterrows():
        count = int(stats[('mastery_score', 'count')])
        mean_score = stats[('mastery_score', 'mean')]
        unique_nodes = int(stats[('node_id', 'nunique')])
        
        print(f"   {difficulty}: {unique_nodes}ä¸ªçŸ¥è¯†ç‚¹, {count}æ¡è®°å½•, å¹³å‡æŒæ¡åº¦:{mean_score:.3f}")

def export_to_csv(data_list, output_file):
    """å¯¼å‡ºæ•°æ®åˆ°CSVæ–‡ä»¶ ğŸ’¾"""
    if not data_list:
        print("âš ï¸ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
        return False
    
    print(f"\nğŸ’¾ å¯¼å‡ºæ•°æ®åˆ°CSVæ–‡ä»¶: {output_file}")
    
    try:
        # å®šä¹‰CSVå­—æ®µ
        fieldnames = [
            'mastery_id',
            'user_id', 'node_id', 'mastery_score', 
            'username', 'node_name', 'node_difficulty', 
            'level', 'node_type'
        ]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            # å†™å…¥è¡¨å¤´
            writer.writeheader()
            
            # å†™å…¥æ•°æ®
            for row in data_list:
                writer.writerow(row)
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(output_file)
        file_size_mb = file_size / (1024 * 1024)
        
        print(f"âœ… CSVæ–‡ä»¶å¯¼å‡ºæˆåŠŸ!")
        print(f"   æ–‡ä»¶è·¯å¾„: {os.path.abspath(output_file)}")
        print(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
        print(f"   è®°å½•æ•°é‡: {len(data_list):,}")
        
        return True
        
    except Exception as e:
        print(f"âŒ CSVå¯¼å‡ºå¤±è´¥: {str(e)}")
        return False

def validate_data_quality(data_list):
    """éªŒè¯æ•°æ®è´¨é‡ ğŸ”"""
    if not data_list:
        return
    
    print(f"\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
    print("-" * 40)
    
    df = pd.DataFrame(data_list)
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_data = df.isnull().sum()
    if missing_data.sum() > 0:
        print(f"âš ï¸ å‘ç°ç¼ºå¤±å€¼:")
        for col, count in missing_data.items():
            if count > 0:
                print(f"   {col}: {count} ä¸ªç¼ºå¤±å€¼")
    else:
        print(f"âœ… æ— ç¼ºå¤±å€¼")
    
    # æ£€æŸ¥æŒæ¡åº¦èŒƒå›´
    invalid_mastery = df[(df['mastery_score'] < 0) | (df['mastery_score'] > 1)]
    if len(invalid_mastery) > 0:
        print(f"âš ï¸ å‘ç° {len(invalid_mastery)} ä¸ªæ— æ•ˆæŒæ¡åº¦å€¼ (ä¸åœ¨0-1èŒƒå›´å†…)")
    else:
        print(f"âœ… æŒæ¡åº¦å€¼èŒƒå›´æ­£å¸¸ (0-1)")
    
    # æ£€æŸ¥é‡å¤è®°å½•
    duplicates = df.duplicated(subset=['user_id', 'node_id'])
    duplicate_count = duplicates.sum()
    if duplicate_count > 0:
        print(f"âš ï¸ å‘ç° {duplicate_count} ä¸ªé‡å¤çš„ç”¨æˆ·-çŸ¥è¯†ç‚¹ç»„åˆ")
    else:
        print(f"âœ… æ— é‡å¤çš„ç”¨æˆ·-çŸ¥è¯†ç‚¹ç»„åˆ")
    
    # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
    print(f"\nğŸ“‹ æ•°æ®å®Œæ•´æ€§:")
    print(f"   ç”¨æˆ·IDèŒƒå›´: {df['user_id'].min()} - {df['user_id'].max()}")
    print(f"   çŸ¥è¯†ç‚¹IDèŒƒå›´: {df['node_id'].min()} - {df['node_id'].max()}")
    print(f"   æŒæ¡åº¦èŒƒå›´: {df['mastery_score'].min():.3f} - {df['mastery_score'].max():.3f}")

def main():
    """ä¸»å‡½æ•° ğŸš€"""
    print("ğŸ“Š ç”¨æˆ·çŸ¥è¯†ç‚¹æŒæ¡åº¦æ•°æ®å¯¼å‡ºå·¥å…·")
    print("=" * 60)
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ æ•°æ®åº“æ–‡ä»¶: {DB_FILE}")
    print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {OUTPUT_CSV}")
    
    try:
        # 1. æå–æ•°æ®
        data_list = extract_mastery_data()
        
        if not data_list:
            print("\nâŒ æ²¡æœ‰æ•°æ®å¯å¤„ç†ï¼Œç¨‹åºé€€å‡º")
            return
        
        # 2. æ•°æ®è´¨é‡æ£€æŸ¥
        validate_data_quality(data_list)
        
        # 3. æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print_statistics(data_list)
        
        # 4. å¯¼å‡ºCSV
        success = export_to_csv(data_list, OUTPUT_CSV)
        
        if success:
            print(f"\nğŸ‰ æ•°æ®å¯¼å‡ºå®Œæˆ!")
            print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
            print(f"   - å¯ä»¥ç”¨Excelæˆ–å…¶ä»–å·¥å…·æ‰“å¼€CSVæ–‡ä»¶è¿›è¡Œè¿›ä¸€æ­¥åˆ†æ")
            print(f"   - æ•°æ®å¯ç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ")
            print(f"   - å»ºè®®å®šæœŸå¯¼å‡ºæ•°æ®è¿›è¡Œå¤‡ä»½")
        else:
            print(f"\nâŒ æ•°æ®å¯¼å‡ºå¤±è´¥")
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
    
    finally:
        print(f"\nâ° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

if __name__ == "__main__":
    main()